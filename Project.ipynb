{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# ML3D Project: Segment Anything Model (SAM) for 3D point clouds"],"metadata":{"id":"gWWb2c6tm6Hd"}},{"cell_type":"markdown","source":["Welcome to our ML3D project! Our mission is to make 3D segmentation through the implementation of the SAM Model [[1]](https://arxiv.org/abs/2304.02643), harnessing the power of 3D point clouds as our input. To achieve this, our approach involves the following process:\n","\n","First, a 2D projection of the point cloud is performed using a spherical projection technique, followed by the application of SAM. Our method employs multiple centers for the sphere, providing a more comprehensive and detailed understanding of the entire space. Next, we translate these 2D masks into 3D points. Ultimately, we employ kNN to craft a comprehensive 3D segmentation of the space.\n","\n","Important: We used ScanNet++ [[2]](https://kaldir.vc.in.tum.de/scannetpp/) as dataset. The scene scans were in the file format .ply. We changed the .ply files to .las files using the open-source tool Cloud Compare [[3]](https://www.cloudcompare.org/)."],"metadata":{"id":"_o8ospm7gp9c"}},{"cell_type":"markdown","source":["All imports:"],"metadata":{"id":"vZtR6K0ZO8wp"}},{"cell_type":"code","source":["import os\n","from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)\n","\n","!cp -r /content/drive/MyDrive/ml3d_project ml3d_project/. # edit correct path\n","os.chdir('/content/drive/MyDrive/ml3d_project/')\n","#!pip uninstall laspy\n","!pip install laspy\n","!pip install trimesh\n","!pip install pillow\n","\n","\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import laspy\n","from PIL import Image, ImageDraw"],"metadata":{"id":"h6PA9H_KkKlF","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1707062683463,"user_tz":-60,"elapsed":17725,"user":{"displayName":"Alejandro Torra Benach","userId":"01872626244483335048"}},"outputId":"f5a33004-daa6-43ec-9881-bfaa829a6f23"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","cp: cannot create directory 'ml3d_project/.': No such file or directory\n","Installing requirements\n"]}]},{"cell_type":"code","source":["!pip install pycocotools\n","!pip install -q jupyter_bbox_widget roboflow dataclasses-json supervision\n","from PIL import Image\n","import json\n","from pycocotools.coco import COCO\n","from skimage import data, color\n","from skimage.transform import rescale, resize, downscale_local_mean\n","import tifffile\n","import random\n","from scipy import ndimage\n","import torch\n","import torch.nn as nn\n","import shutil\n","import sys\n","import cv2\n","import supervision as sv"],"metadata":{"id":"TA4SW6TUPFie"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# All necessary functions for the computation of the segmented point cloud"],"metadata":{"id":"qs_5qNqFKfFS"}},{"cell_type":"code","source":["def generate_spherical_image_flip(center_coordinates, point_cloud, colors, resolution_y, camera_angle):\n","\n","    R = np.array([[np.cos(np.radians(camera_angle)), -np.sin(np.radians(camera_angle)), 0],\n","                  [np.sin(np.radians(camera_angle)), np.cos(np.radians(camera_angle)), 0],\n","                  [0, 0, 1]])\n","\n","    translated_points = point_cloud - center_coordinates\n","\n","    transformed_points = np.dot(translated_points, R.T)\n","\n","    theta = np.arctan2(transformed_points[:, 1], transformed_points[:, 0])\n","    phi = np.arccos(transformed_points[:, 2] / np.linalg.norm(transformed_points, axis=1))\n","\n","    x = (theta + np.pi) / (2 * np.pi) * (2 * resolution_y)\n","    y = phi / np.pi * resolution_y\n","\n","    resolution_x = 2 * resolution_y\n","    image = np.zeros((resolution_y, resolution_x, 3), dtype=np.uint8)\n","\n","    mapping = np.full((resolution_y, resolution_x), -1, dtype=int)\n","\n","    for i in range(len(translated_points)):\n","        ix = np.clip(int(x[i]), 0, resolution_x - 1)\n","        iy = np.clip(int(y[i]), 0, resolution_y - 1)\n","        if mapping[iy, ix] == -1 or np.linalg.norm(transformed_points[i]) < np.linalg.norm(transformed_points[mapping[iy, ix]]):\n","            mapping[iy, ix] = i\n","            image[iy, ix] = colors[i]\n","    return image, mapping"],"metadata":{"id":"Nzke9zsnKfhU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def color_point_cloud(image_path, point_cloud, mapping):\n","    image = cv2.imread(image_path)\n","    h, w = image.shape[:2]\n","    modified_point_cloud = np.zeros((point_cloud.shape[0], point_cloud.shape[1]+3), dtype=np.float32)\n","    modified_point_cloud[:, :3] = point_cloud\n","    for iy in range(h):\n","        for ix in range(w):\n","            point_index = mapping[iy, ix]\n","            if point_index != -1:\n","                color = image[iy, ix]\n","                modified_point_cloud[point_index, 3:] = color\n","    return modified_point_cloud"],"metadata":{"id":"DTVJ3rd-v2a7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def export_point_cloud(cloud_path, modified_point_cloud):\n","    header = laspy.LasHeader(point_format=3, version=\"1.2\")\n","    header.add_extra_dim(laspy.ExtraBytesParams(name=\"random\", type=np.int32))\n","\n","    las_o = laspy.LasData(header)\n","    las_o.x = modified_point_cloud[:,0]\n","    las_o.y = modified_point_cloud[:,1]\n","    las_o.z = modified_point_cloud[:,2]\n","    las_o.red = modified_point_cloud[:,3]\n","    las_o.green = modified_point_cloud[:,4]\n","    las_o.blue = modified_point_cloud[:,5]\n","    las_o.write(cloud_path)\n","\n","    print(\"Export succesful at: \", cloud_path)\n","    return"],"metadata":{"id":"j9CX-TUTv8y_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Spherical Projection of 3D PointClouds\n"],"metadata":{"id":"ULY1rzMqMsVe"}},{"cell_type":"code","source":["resolution = 1024\n","camera_angle = [0]\n","spherical_images = []\n","mappings = []\n","random_point_clouds = []"],"metadata":{"id":"lPCKi5WeM3Sm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["directory_path = '/content/drive/MyDrive/ml3d_project/data/pointclouds'\n","directory_output = '/content/drive/MyDrive/ml3d_project/data/images'\n","\n","for i in range(1, 11):\n","    file_path = directory_path + f'/pc_aligned_{i}.las'\n","    las = laspy.read(file_path)\n","\n","    coords = np.vstack((las.x, las.y, las.z))\n","    point_cloud = coords.transpose()\n","\n","    r = (las.red/65535*255).astype(int)\n","    g = (las.green/65535*255).astype(int)\n","    b = (las.blue/65535*255).astype(int)\n","    colors = np.vstack((r,g,b)).transpose()\n","\n","    num_points = len(point_cloud)\n","    random_indices = np.random.choice(num_points, size=num_points // 2, replace=False)\n","    random_point_cloud = point_cloud[random_indices]\n","    random_point_clouds.append(random_point_cloud)\n","    random_colors = colors[random_indices]\n","    #del las\n","\n","    center = np.mean(random_point_cloud, axis=0)\n","    # print(center)\n","\n","    spherical_image, mapping = generate_spherical_image_flip(center, random_point_cloud, random_colors, resolution, angle)\n","    spherical_images.append(spherical_image)\n","    mappings.append(mapping)\n","\n","    spherical_image = Image.fromarray(spherical_image)\n","    spherical_image.save(directory_output + f'/pc_aligned_spherical_{i}.jpg')"],"metadata":{"id":"fWgTVqhlM3Qt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Plotting an image with matplotlib\n","fig = plt.figure(figsize=(np.shape(spherical_images[0])[1]/72, np.shape(spherical_images[0])[0]/72))\n","fig.add_axes([0,0,1,1])\n","plt.imshow(spherical_images[0])\n","plt.axis('off')"],"metadata":{"id":"A94hs_l6M3Oc"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# SAM Segmentation"],"metadata":{"id":"ZoYRhXZEO4y7"}},{"cell_type":"code","source":["gdrive_path = '/content/drive/MyDrive/ml3d_project'\n","os.chdir(gdrive_path)\n","HOME = os.getcwd()\n","print(\"HOME:\", HOME)"],"metadata":{"id":"v5moc-RfM3MC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Install Segment Anything Model (SAM) and other dependencies\n","%cd {HOME}\n","!{sys.executable} -m pip install 'git+http://github.com/facebookresearch/segment-anything.git'"],"metadata":{"id":"lR-P_1NxM3Jz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Download weights from the database\n","path_weights = \"/content/drive/MyDrive/ml3d_project/SAMWeights\"\n","%cd $path_weights\n","\n","!wget -q https://dl.fbaipublicfiles.com/segment_anything/sam_vit_h_4b8939.pth"],"metadata":{"id":"cUWy2f9qM3Hl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["CHECKPOINT_PATH = os.path.join(path_weights, \"sam_vit_h_4b8939.pth\")\n","print(CHECKPOINT_PATH, \"; exist:\", os.path.isfile(CHECKPOINT_PATH))"],"metadata":{"id":"uM_qUyckM3FC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Load the model\n","import torch\n","torch.cuda.empty_cache()\n","DEVICE = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n","MODEL_TYPE = \"vit_h\""],"metadata":{"id":"aoayRQN5Pa7g"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from segment_anything import sam_model_registry, SamAutomaticMaskGenerator, SamPredictor\n","\n","sam = sam_model_registry[MODEL_TYPE](checkpoint=CHECKPOINT_PATH).to(device=DEVICE)"],"metadata":{"id":"jJPPqszGPa5I"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Automatic Mask Generator\n","mask_generator = SamAutomaticMaskGenerator(sam)"],"metadata":{"id":"slSRfrg8Pa2v"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["sam_results = []\n","\n","for i in range(1, 11):\n","  IMAGE_PATH = f\"/content/drive/MyDrive/ml3d_project/data/images/pc_aligned_{i}.jpg\"\n","  print(IMAGE_PATH)\n","  image_bgr = cv2.imread(IMAGE_PATH)\n","  image_rgb = cv2.cvtColor(image_bgr, cv2.COLOR_BGR2RGB)\n","  image_rescaled = rescale(image_rgb, 0.50, anti_aliasing=False)\n","\n","  sam_result = mask_generator.generate(image_rgb)\n","\n","  sam_results.append(sam_result)\n","\n","  mask_annotator = sv.MaskAnnotator(color_lookup=sv.ColorLookup.INDEX)\n","\n","  detections = sv.Detections.from_sam(sam_result=sam_result)\n","\n","  annotated_image = mask_annotator.annotate(scene=image_bgr.copy(), detections=detections)\n","\n","  sv.plot_images_grid(\n","    images=[image_bgr, annotated_image],\n","    grid_size=(1, 2),\n","    titles=['source image', 'segmented image']\n","  )\n","\n","  cv2.imwrite(f'/content/drive/MyDrive/ml3d_project/data/segmented_images/segmented_image_{i}.jpg', annotated_image)"],"metadata":{"id":"sdHssDwrPa0B"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 2D to 3D Mapping\n","\n","*   After the spherical projection and segmentation, we map our images back to 3Dspace\n","*   Also, export the Colored Point Cloud into a las file"],"metadata":{"id":"S_73-hkgqG_5"}},{"cell_type":"code","source":["for i in range(1,11):\n","\n","  image_path = f'/content/drive/MyDrive/ml3d_project/data/segmented_images/segmented_image_{i}.jpg'\n","  #point_cloud = f'/content/drive/MyDrive/ml3d_project/data/pointclouds/pc_aligned_{i}.las'\n","  j = i-1\n","  mapping = mappings[j]\n","  point_cloud = random_point_clouds[j]\n","\n","\n","  modified_point_cloud = color_point_cloud(image_path, point_cloud, mapping)\n","  export_point_cloud(f'/content/drive/MyDrive/ml3d_project/output/segmented_pointclouds/pc_aligned_{i}.las', modified_point_cloud)"],"metadata":{"id":"4MA2S2glPavi"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Now you can use Cloud Compare to view the segmented pointcloud.\n","\n"],"metadata":{"id":"BN-OWTCysWgD"}},{"cell_type":"markdown","source":["# k-NN"],"metadata":{"id":"D1cs6Z0stFPU"}},{"cell_type":"markdown","source":["Color Assignment Logic: Assign the most frequent (mode) color among the nearest neighbors. This approach is useful to ensure that the assigned color is actually one of the colors present in the neighborhood, rather than a blend that might not exist.\n","This approach should classify unsegmented points based on the colors of their nearest segmented neighbors, helping to fill in unsegmented regions of the point cloud with appropriate colors."],"metadata":{"id":"QgiSQL5DtKOh"}},{"cell_type":"code","source":["from sklearn.neighbors import NearestNeighbors\n","from scipy.stats import mode\n","\n","directory_path = '/content/drive/MyDrive/ml3d_project/output/segmented_pointclouds'\n","output_directory = '/content/drive/MyDrive/ml3d_project/output/kNN_output'\n","for i in range(1, 11):\n","    file_path = directory_path + f'/pc_aligned_{i}.las'\n","\n","    las_file = laspy.read(file_path)\n","    points = np.vstack((las_file.x, las_file.y, las_file.z)).transpose()\n","    colors = np.vstack((las_file.red, las_file.green, las_file.blue)).transpose()\n","    unassigned_mask = np.all(colors == 0, axis=1)\n","    assigned_mask = ~unassigned_mask\n","\n","    X_train = points[assigned_mask]\n","    X_test = points[unassigned_mask]\n","    colors_train = colors[assigned_mask]\n","\n","    nn = NearestNeighbors(n_neighbors=10)\n","    nn.fit(X_train)\n","\n","    distances, indices = nn.kneighbors(X_test)\n","\n","    mode_colors, _ = mode(colors_train[indices], axis=1)\n","    colors_test = mode_colors.squeeze()\n","    colors[unassigned_mask] = colors_test.astype(int)\n","\n","    new_las = laspy.create(point_format=las_file.header.point_format, file_version=las_file.header.version)\n","    new_las.x, new_las.y, new_las.z = points.transpose()\n","    new_las.red, new_las.green, new_las.blue = colors.transpose()\n","\n","    new_las_path = output_directory + f'/kNN_segmented_pointcloud_final_{i}.las'\n","    new_las.write(new_las_path)\n","    print(f\"Updated LAS file saved to: {new_las_path}\")"],"metadata":{"id":"OKcOFmwXPabp"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Again, you can now take the output point cloud files and use Cloud Compare to view the segmented pointcloud."],"metadata":{"id":"YAcktY_bxcD3"}},{"cell_type":"markdown","source":["# Bibliography\n","\n","[1] Segment Anything\n","Kirillov et al.\n","https://arxiv.org/abs/2304.02643\n","\n","[2] Dataset: ScanNet++\n","https://kaldir.vc.in.tum.de/scannetpp/\n","\n","[3] Cloud Compare:\n","https://www.cloudcompare.org/\n","\n"],"metadata":{"id":"DBzBwX7zmuhk"}}]}